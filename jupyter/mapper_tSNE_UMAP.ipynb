{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c064678-637e-4eb8-8089-7e2b21d30e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kmapper as km\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import DBSCAN\n",
    "import json\n",
    "from dm_lib import load_dataframe_from_disk\n",
    "from dm_lib import column_str, attributes, create_dataframe_from_columns, undersample_data, oversample_with_smote\n",
    "\n",
    "def create_mapper(df1, df2,method,param_value,filename,label):\n",
    "    try:\n",
    "        df3 = pd.merge(df1, df2, on='transaction_id', how='left')\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "        numeric_columns = df1.drop(['transaction_id', 'fraud'], axis=1).columns\n",
    "        df1_scaled = scaler.fit_transform(df1[numeric_columns])\n",
    "        mapper = km.KeplerMapper(verbose=1)\n",
    "        if method == 'tsne':\n",
    "            lens = TSNE(n_components=2, perplexity=param_value, random_state=42).fit_transform(df1_scaled)\n",
    "        elif method == 'umap':\n",
    "            lens = UMAP(n_components=2, n_neighbors=param_value, random_state=42).fit_transform(df1_scaled)\n",
    "\n",
    "        n_cubes_values = [5, 10, 15]\n",
    "        perc_overlap_values = [0.3, 0.5, 0.7]\n",
    "        eps_values = [0.3, 0.5, 0.7]\n",
    "        min_samples_values = [3, 5, 7]\n",
    "\n",
    "        best_params = None\n",
    "        best_num_nodes = 0\n",
    "        best_graph = None\n",
    "\n",
    "        for n_cubes in n_cubes_values:\n",
    "            for perc_overlap in perc_overlap_values:\n",
    "                for eps in eps_values:\n",
    "                    for min_samples in min_samples_values:\n",
    "                        print(f\"Trying parameters: n_cubes={n_cubes}, perc_overlap={perc_overlap}, eps={eps}, min_samples={min_samples}\")\n",
    "                        \n",
    "                        cover = km.Cover(n_cubes=n_cubes, perc_overlap=perc_overlap)\n",
    "                        clusterer = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "                        graph = mapper.map(lens, df1_scaled, cover=cover, clusterer=clusterer)\n",
    "\n",
    "                        num_nodes = len(graph['nodes'])\n",
    "                        num_edges = len(graph['links'])\n",
    "\n",
    "                        if num_nodes > best_num_nodes:\n",
    "                            best_num_nodes = num_nodes\n",
    "                            best_params = (n_cubes, perc_overlap, eps, min_samples)\n",
    "                            best_graph = graph\n",
    "\n",
    "        if best_graph is None:\n",
    "            raise Exception(\"Nav atrasti piemēroti parametri\")\n",
    "    \n",
    "        tooltip_columns = df2.columns.tolist()\n",
    "        tooltips = df[tooltip_columns].apply(lambda row: json.dumps(row.to_dict(), default=str), axis=1).values\n",
    "\n",
    "        html = mapper.visualize(graph, path_html=filename,\n",
    "                                custom_tooltips=tooltips, title=label)\n",
    "    \n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(html)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "for setName in ('B'):#'A','B'\n",
    "    df = load_dataframe_from_disk('dataSet_'+setName+'.pkl')\n",
    "    for entry in attributes:\n",
    "        if entry['type'] not in ('cart','relieff'):\n",
    "            continue\n",
    "        column_list = entry['value'][:]\n",
    "        column_list.insert(0, 'transaction_id')\n",
    "        column_list.insert(0, 'fraud')\n",
    "        mapper_df = create_dataframe_from_columns(df, column_list)\n",
    "        tooltip_df = create_dataframe_from_columns(df, column_list)\n",
    "        #for p in [50]:\n",
    "        #    f = 'mapper/mapper_'+entry['name']+'_tSNE_p'+str(p)+'_set_'+setName+'.html'\n",
    "        #    title = 'Datu kopa: '+setName+', atribūtu kopa:'+entry['name']+', t-SNE perplexity:'+str(p)\n",
    "        #    create_mapper(mapper_df,tooltip_df,'tsne',p,f,title)\n",
    "        for p in [50]:\n",
    "            f = 'mapper/mapper_'+entry['name']+'_UMAP_n'+str(p)+'_set_'+setName+'.html'\n",
    "            title = 'Datu kopa: '+setName+', atribūtu kopa:'+entry['name']+', UMAP n_neighbors:'+str(p)\n",
    "            create_mapper(mapper_df,tooltip_df,'umap',p,f,title)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
