{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c2b0b-b7e8-4c41-a80f-3f7f887db02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dm_lib import read_sql_complete, column_str, attributes, create_dataframe_from_columns, undersample_data, oversample_with_smote\n",
    "from dm_lib import load_dataframe_from_disk\n",
    "from dm_lib import tranSet_A, tranSet_B, tranSet_C, tranSet_D\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import os\n",
    "import re\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    forbidden_chars = r'[<>:\"/\\\\|?*, ]'\n",
    "    sanitized = re.sub(forbidden_chars, '_', filename)\n",
    "    return sanitized\n",
    "\n",
    "def preprocess_data(df, target_column, reduction_method='pca', n_components=2):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    if reduction_method == 'PCA':\n",
    "        reducer = PCA(n_components=n_components)\n",
    "    elif reduction_method == 't-SNE':\n",
    "        reducer = TSNE(n_components=n_components,perplexity=50)\n",
    "    elif reduction_method == 'UMAP':\n",
    "        reducer = umap.UMAP(n_components=n_components,n_neighbors=50)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid reduction method.\")\n",
    "\n",
    "    X_reduced = reducer.fit_transform(X_scaled)\n",
    "    return X_reduced, y\n",
    "\n",
    "def train_models(X, y):\n",
    "    models = {\n",
    "        'Nejaušais mežs': RandomForestClassifier(),\n",
    "        'Naivais Beijess': GaussianNB(),\n",
    "        'Atbalsta vektoru mašīnas': SVC(probability=True),\n",
    "        'Loģistiskā regresija': LogisticRegression()\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X, y)\n",
    "    return models\n",
    "\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    metrics = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "        metrics[name] = {\n",
    "            'fpr': fpr, 'tpr': tpr, 'roc_auc': roc_auc,\n",
    "            'precision': precision, 'recall': recall, 'pr_auc': pr_auc, 'f1_score': f1,\n",
    "            'confusion_matrix': cm, 'mcc': mcc, 'kappa': kappa\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title, filename):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Prognozētā klase\")\n",
    "    plt.ylabel(\"Patiesā klase\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_metrics(metrics_dict, output_dir):\n",
    "    class_names = ['Īsta transakcija', 'Krāpnieciska transakcija']\n",
    "    rows = []\n",
    "\n",
    "    for method, metrics in metrics_dict.items():\n",
    "        plt.figure(figsize=(14, 7))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        for name, metric in metrics.items():\n",
    "            plt.plot(metric['fpr'], metric['tpr'], label=f'{name} (AUC = {metric[\"roc_auc\"]:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('Kļūdainas atbilsmes koeficients')\n",
    "        plt.ylabel('Pareizas atbilsmes koeficients')\n",
    "        plt.title(f'ROC līkne ({method})')\n",
    "        plt.legend(loc='best')\n",
    "        roc_filename = os.path.join(output_dir, f\"roc_curve_{sanitize_filename(method)}.png\")\n",
    "        plt.savefig(roc_filename)\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for name, metric in metrics.items():\n",
    "            plt.plot(metric['recall'], metric['precision'], label=f'{name} (AUC = {metric[\"pr_auc\"]:.2f})')\n",
    "        plt.xlabel('Pārklājums')\n",
    "        plt.ylabel('Precizitāte')\n",
    "        plt.title(f'Precizitātes-Pārklājuma līkne ({method})')\n",
    "        plt.legend(loc='best')\n",
    "        pr_filename = os.path.join(output_dir, f\"pr_curve_{sanitize_filename(method)}.png\")\n",
    "        plt.savefig(pr_filename)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        for name, metric in metrics.items():\n",
    "            cm_filename = os.path.join(output_dir, f\"confusion_matrix_{sanitize_filename(method)}_{name}.png\")\n",
    "            plot_confusion_matrix(metric['confusion_matrix'], class_names, f'Pārpratumu matrica ({method} - {name})', cm_filename)\n",
    "            print(f\"Confusion matrix for {name} ({method}) saved to: {cm_filename}\")\n",
    "\n",
    "            rows.append({\n",
    "                'Method': method,\n",
    "                'Model': name,\n",
    "                'ROC AUC': metric['roc_auc'],\n",
    "                'PR AUC': metric['pr_auc'],\n",
    "                'F1 Score': metric['f1_score'],\n",
    "                'MCC': metric['mcc'],\n",
    "                'Cohen\\'s Kappa': metric['kappa']\n",
    "            })\n",
    "\n",
    "    metrics_df = pd.DataFrame(rows)\n",
    "    metrics_table_filename = os.path.join(output_dir, \"metrics_table.csv\")\n",
    "    metrics_df.to_csv(metrics_table_filename, sep=',', decimal=',', index=False)\n",
    "\n",
    "    plt.figure(figsize=(12, len(metrics_df) * 0.4 + 1))\n",
    "    plt.table(cellText=metrics_df.values, colLabels=metrics_df.columns, cellLoc='center', loc='center')\n",
    "    plt.axis('off')\n",
    "    table_filename = os.path.join(output_dir, \"metrics_table.png\")\n",
    "    plt.savefig(table_filename)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for method, metrics in metrics_dict.items():\n",
    "        f1_scores = [metric['f1_score'] for metric in metrics.values()]\n",
    "        plt.plot(list(metrics.keys()), f1_scores, marker='o', label=method.upper())\n",
    "    plt.xlabel('Modeļi')\n",
    "    plt.ylabel('F1 mērs')\n",
    "    plt.title('F1 mēra salīdzinājums')\n",
    "    plt.legend(loc='best')\n",
    "    f1_filename = os.path.join(output_dir, \"f1_score_comparison.png\")\n",
    "    plt.savefig(f1_filename)\n",
    "    plt.show()\n",
    "\n",
    "    for metric_name, ylabel in zip(['mcc', 'kappa'], ['MKK', 'Cohen\\'s Kappa']):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for method, metrics in metrics_dict.items():\n",
    "            scores = [metric[metric_name] for metric in metrics.values()]\n",
    "            plt.plot(list(metrics.keys()), scores, marker='o', label=method)\n",
    "        plt.xlabel('Modeļi')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title(f'{ylabel} salīdzinājums')\n",
    "        plt.legend(loc='best')\n",
    "        filename = os.path.join(output_dir, f\"{metric_name}_comparison.png\")\n",
    "        plt.savefig(filename)\n",
    "        plt.show()\n",
    "        print(f\"{ylabel} comparison plot saved to: {filename}\")\n",
    "\n",
    "metrics_dict = {}    \n",
    "\n",
    "for setName in ('B'):#'A','B'\n",
    "    df = load_dataframe_from_disk('dataSet_'+setName+'.pkl')\n",
    "    for entry in attributes:\n",
    "        if entry['type'] in ('aggregated','relieff','cart'):\n",
    "            continue\n",
    "        for type in ('o','u',''):\n",
    "            column_list = entry['value'][:]\n",
    "            column_list.insert(0, 'fraud')\n",
    "            source_df = create_dataframe_from_columns(df,column_list)\n",
    "            if type == 'o':\n",
    "                classifier_df = oversample_with_smote(source_df, 'fraud')\n",
    "            elif type == 'u':\n",
    "                classifier_df = undersample_data(source_df, 'fraud', desired_ratio=1)\n",
    "            else:\n",
    "                classifier_df = source_df\n",
    "\n",
    "            target_column = 'fraud'\n",
    "            \n",
    "            reduction_methods = ['UMAP','t-SNE','PCA']\n",
    "            \n",
    "            for method in reduction_methods:\n",
    "                X_reduced, y = preprocess_data(classifier_df, target_column, reduction_method=method)\n",
    "        \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.3, random_state=42)\n",
    "\n",
    "                models = train_models(X_train, y_train)\n",
    "\n",
    "                id = 'Datu kopa: '+setName+type+', atribūtu kopa: '+entry['name']+', '+method\n",
    "\n",
    "                metrics = evaluate_models(models, X_test, y_test)\n",
    "                metrics_dict[id] = metrics\n",
    "\n",
    "plot_metrics(metrics_dict, 'classifiers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
